Model,Model Family,Model Size (B),Pretraining Data Size (T),FLOPs (1E21),MMLU,ARC-C,HellaSwag,Winograd,TruthfulQA,GSM8K,XWinograd,HumanEval
meta-llama/Llama-2-7b-hf,Llama-2,7.0,2.0,84.0,0.4379609636092418,0.5307167235494881,0.7774347739494125,0.7403314917127072,0.3898020280158031,0.1448066717210007,0.7548812733233227,0.1280487804878048
huggyllama/llama-7b,Llama,6.7,1.0,40.2,0.3569330638795117,0.5093856655290102,0.7781318462457678,0.7142857142857143,0.3432793294414406,0.0803639120545868,0.693204494643244,0.1280487804878048
meta-llama/Meta-Llama-3-8B,Llama-3,8.0,15.0,720.0,0.6649495492503578,,0.8201553475403306,0.771112865035517,0.4395226511050948,0.4533737680060652,0.8011516647345902,0.3841463414634146
meta-llama/Meta-Llama-3.1-8B,Llama-3.1,8.0,15.0,720.0,0.6598646709925372,0.5767918088737202,0.8167695678151763,0.7837411207576953,0.4522366479705642,0.4579226686884003,0.7994280519549424,0.3719512195121951
Qwen/Qwen1.5-7B,Qwen1.5,7.0,4.0,168.0,0.6197002168140558,0.5418088737201365,0.7851025692093209,0.712707182320442,0.5108227702127015,0.535253980288097,0.7523613984226699,0.3475609756097561
Qwen/Qwen1.5-4B,Qwen1.5,4.0,2.4,57.6,0.5652351963993337,0.4846416382252559,0.7157936666002789,0.6621941594317285,0.4727318979180884,0.5223654283548143,0.6887854394246548,0.2621951219512195
Qwen/Qwen1.5-1.8B,Qwen1.5,1.8,2.4,25.92,0.4670838530175782,0.378839590443686,0.6142202748456482,0.6029992107340174,0.3942781424608406,0.335860500379075,0.643824662703727,0.1829268292682926
Qwen/Qwen1.5-0.5B,Qwen1.5,0.5,2.4,7.199999999999999,0.3935334081217579,0.3148464163822526,0.4905397331208923,0.5722178374112076,0.3829926844374736,0.1630022744503411,0.5756214927787449,0.1158536585365853
Qwen/Qwen-7B,Qwen,7.0,2.4,100.8,0.5983879208119841,0.5136518771331058,0.7847042421828321,0.7269139700078927,0.4778593054989757,0.4495830174374526,0.7345767284317054,0.3170731707317073
Qwen/Qwen2-7B,Qwen2,7.0,,,0.7194919059961393,0.6109215017064846,0.8063134833698467,0.7624309392265194,0.5434989796584184,0.7445034116755117,0.7820493214765835,0.4695121951219512
Qwen/Qwen2-1.5B,Qwen2,1.5,,,0.5719800134865977,0.4385665529010238,0.6671977693686517,0.6464088397790055,0.4588177706805861,0.5564821834723275,0.7323140692488941,0.3353658536585366
Qwen/Qwen2-0.5B,Qwen2,0.5,,,0.4516942941579787,0.3191126279863481,0.4869547898824935,0.5595895816890292,0.3969971150638361,0.3457164518574678,0.6274352930315701,0.2317073170731707
mistralai/Mistral-7B-v0.1,Mistral,7.3,,,0.6416448378492244,0.5998293515358362,0.8331009759012149,0.7861089187056038,0.4215317106968115,0.3707354056103108,0.7818571022215156,0.274390243902439
01-ai/Yi-6B,Yi,6.0,3.0,108.0,0.6410709139827397,0.5554607508532423,0.7656841266679945,0.7419100236779794,0.4196160749943391,0.1213040181956027,0.7238791258822254,0.1585365853658536
01-ai/Yi-1.5-9B,Yi-1.5,9.0,3.6,194.4,0.7099770832156586,0.6194539249146758,0.8031268671579367,0.7797947908445146,0.4667455659668617,0.6277482941622441,0.7419586923775754,0.4207317073170731
01-ai/Yi-1.5-6B,Yi-1.5,6.0,3.6,129.6,0.6490914549693695,0.5716723549488054,0.7797251543517227,0.7529597474348856,0.4401230806191787,0.4981046247156937,0.7137746099450846,0.3658536585365853
google/gemma-7b,Gemma,7.0,6.0,252.0,0.6602745725247715,0.6109215017064846,0.8247361083449513,0.7845303867403315,0.4490548840372056,0.5276724791508719,0.7838998559701617,0.3353658536585366
google/gemma-2b,Gemma,2.0,6.0,72.0,0.4177314644002597,0.4837883959044368,0.7176857199761004,0.6629834254143646,0.3308443428097746,0.1690674753601213,0.7093183574434074,0.2317073170731707
google/gemma-2-9b,Gemma-2,9.0,8.0,432.0,0.713,0.684,0.819,0.806,0.4643743533315447,0.686,0.8301511186747728,0.3963414634146341
google/gemma-2-2b,Gemma-2,2.0,2.0,24.0,0.522,0.557,0.729,0.713,0.4133173557711077,0.243,0.7589869855274696,0.1951219512195122
tiiuae/falcon-7b,Falcon,7.0,1.5,63.0,0.2778547015328594,0.4786689419795222,0.7813184624576778,0.7237569060773481,0.34263825539848,0.0462471569370735,0.7175723631696234,
tiiuae/falcon-rw-1b,Falcon,1.0,0.35,2.1,0.2528031884754075,0.3506825938566553,0.6356303525194185,0.6203630623520127,0.3595559898003175,0.0053070507960576,0.5354987006020437,
microsoft/phi-2,Phi,2.7,1.4,22.680000000000003,0.5792026667108577,0.6100682593856656,0.7491535550687114,0.7348066298342542,0.4423687837225679,0.5496588324488249,0.5266663910651852,0.4939024390243902
microsoft/phi-1_5,Phi,1.3,0.15,1.1700000000000002,0.4388646778419788,0.5290102389078498,0.6379207329217288,0.7221783741120757,0.4088993856119402,0.1243366186504928,0.5111127837745847,0.3414634146341463
EleutherAI/pythia-1b-deduped,Pythia,1.0,0.3,1.7999999999999998,0.2427106456015119,0.2909556313993174,0.4965146385182235,0.5359116022099447,0.389393782096148,0.0113722517058377,0.560991660200979,0.0426829268292682
EleutherAI/pythia-410m-deduped,Pythia,0.41,0.3,0.738,0.2598881956235394,0.2482935153583617,0.4128659629555865,0.5438042620363063,0.4094757859220677,0.00303260045489,0.5363121645812539,0.0121951219512195
EleutherAI/pythia-6.9b-deduped,Pythia,6.9,0.3,12.420000000000002,0.2648094407333687,0.4129692832764505,0.6704839673371839,0.6408839779005525,0.3519458488266109,0.0166793025018953,0.6524704540748439,0.0853658536585365
EleutherAI/pythia-2.8b-deduped,Pythia,2.8,0.3,5.039999999999999,0.2678463743419206,0.3626279863481229,0.6065524795857399,0.6022099447513812,0.3555978234501585,0.0083396512509476,0.6399890469310126,0.048780487804878
EleutherAI/pythia-70m-deduped,Pythia,0.07,0.3,0.126,0.2526050703920223,0.2107508532423208,0.2716590320653256,0.4964483030781373,0.4751438547560591,0.0,0.5100999142283605,0.0
EleutherAI/pythia-1.4b-deduped,Pythia,1.4,0.3,2.52,0.2555549665134659,0.3267918088737201,0.5495917147978491,0.5730071033938438,0.3865846445222244,0.0083396512509476,0.5940628537455149,0.0426829268292682
EleutherAI/pythia-160m-deduped,Pythia,0.16,0.3,0.288,0.248605749975484,0.2406143344709897,0.3138816968731328,0.5138121546961326,0.443404463764025,0.0022744503411675,0.5235998028121159,0.0
bigscience/bloom-560m,BLOOM,0.56,0.341,1.14576,0.2421541212062042,0.2474402730375426,0.371539533957379,0.5193370165745856,0.4244428174437842,0.00303260045489,0.5785515149379533,0.0060975609756097
bigscience/bloom-1b1,BLOOM,1.1,0.341,2.2506000000000004,0.2670214825620786,0.2832764505119454,0.4278032264489145,0.5501183898973955,0.4179716703713765,0.0022744503411675,0.6095129616265768,0.0
bigscience/bloom-3b,BLOOM,3.0,0.341,6.138000000000001,0.2659250919932785,0.3575085324232082,0.54371639115714,0.5761641673243884,0.4057246298885345,0.0151630022744503,0.664767416287304,0.0182926829268292
bigscience/bloom-7b1,BLOOM,7.1,0.341,14.526599999999998,0.262462223757257,0.4112627986348123,0.6199960167297351,0.654301499605367,0.3889784219035787,0.0136467020470053,0.697719119485617,0.048780487804878
EleutherAI/gpt-neo-2.7B,GPT-Neo/J,2.7,0.42,6.804000000000001,0.2645397884474629,0.333617747440273,0.5624377614021111,0.6006314127861089,0.3977795990878021,0.0128885519332827,0.573989468939644,0.0670731707317073
EleutherAI/gpt-neo-1.3B,GPT-Neo/J,1.3,0.38,2.9640000000000004,0.2482165549913705,0.3122866894197952,0.4846644094801832,0.569060773480663,0.3962930604436832,0.0045489006823351,0.5610910983301023,0.0365853658536585
EleutherAI/gpt-neo-125m,GPT-Neo/J,0.125,0.3,0.2249999999999999,0.2597039137782334,0.2295221843003413,0.3026289583748257,0.5177584846093133,0.455761630633801,0.00303260045489,0.5022135306511495,0.0060975609756097
EleutherAI/gpt-j-6b,GPT-Neo/J,6.05,0.402,14.5926,0.2678399935864076,0.4138225255972696,0.675363473411671,0.65982636148382,0.359624729495078,0.0295678544351781,0.6810776559839498,0.1158536585365853
facebook/opt-6.7b,OPT,6.7,0.18,7.236000000000001,0.2456740659904941,0.3916382252559727,0.6866162119099781,0.65982636148382,0.3512214978869498,0.0098559514783927,0.5942690810662132,0.0060975609756097
facebook/opt-1.3b,OPT,1.3,0.18,1.404,0.2496304582561669,0.295221843003413,0.545309699263095,0.5974743488555643,0.387106757904831,0.001516300227445,0.5440287610593753,0.0
facebook/opt-350m,OPT,0.35,0.18,0.3779999999999999,0.2602309674346793,0.2354948805460751,0.367257518422625,0.526440410418311,0.4082853277784469,0.00303260045489,0.5181109402408465,0.0
facebook/opt-2.7b,OPT,2.7,0.18,2.9160000000000004,0.2543197294843227,0.3395904436860068,0.6143198566022705,0.6195737963693765,0.3742541799029018,0.0022744503411675,0.5684868941265007,0.0
facebook/opt-125m,OPT,0.125,0.18,0.135,0.2601558755564414,0.2286689419795221,0.3146783509261103,0.516179952644041,0.4286875802615585,0.0007581501137225,0.4986842384279715,0.0
mosaicml/mpt-7b,MPT,7.0,1.0,42.0,0.2806843136121969,0.4769624573378839,0.7753435570603465,0.7213891081294396,0.3354506043570123,0.0401819560272934,0.714400117960088,0.1646341463414634
facebook/xglm-564M,XGLM,0.564,0.5,1.6919999999999995,0.2517966357007282,0.2457337883959044,0.3464449312885879,0.5224940805051302,0.4043205877039627,0.0022744503411675,0.5855090554685282,0.0
facebook/xglm-1.7B,XGLM,1.7,0.5,5.1,0.2510041645690995,0.2585324232081911,0.4567815176259709,0.5390686661404893,0.3720634151696304,0.0075815011372251,0.6306808718012892,0.0
facebook/xglm-4.5B,XGLM,4.5,0.5,13.5,0.254299777191496,0.3148464163822526,0.5794662417845051,0.5493291239147593,0.3583939485040638,0.0022744503411675,0.6585139569181357,0.0
facebook/xglm-7.5B,XGLM,7.5,0.5,22.5,0.2778866807166943,0.3412969283276451,0.6077474606652061,0.5872138910812944,0.3666152388235458,0.0022744503411675,0.6955505613435582,0.0
codellama/CodeLlama-7b-hf,CodeLlama,7.0,2.52,105.84,0.3112206482914894,0.3993174061433447,0.6080462059350727,0.6400947119179163,0.3782167557307672,0.0515542077331311,0.7297239600242453,0.3353658536585366
bigcode/starcoderbase-1b,StarCoder,1.0,1.0,6.0,0.266738815642615,0.2269624573378839,0.3430591515634336,0.4996053670086819,0.4578928664903403,0.0090978013646702,0.56173933366138,0.146
bigcode/starcoderbase-3b,StarCoder,3.0,1.0,18.0,0.2735280049306773,0.2585324232081911,0.3910575582553276,0.5114443567482242,0.4305451198786013,0.0174374526156178,0.5976355730660291,0.177
bigcode/starcoderbase-7b,StarCoder,7.0,1.0,42.0,0.2844643845271117,0.2986348122866894,0.4386576379207329,0.5438042620363063,0.4046263361255611,0.0545868081880212,0.5978311244584498,0.244
bigcode/starcoder2-7b,StarCoder2,7.0,3.7,155.4,0.4121331864479663,0.3831058020477815,0.5191196972714599,0.5919494869771112,0.4199349765667209,0.2509476876421531,0.6200898066999413,0.354
bigcode/starcoder2-3b,StarCoder2,3.0,3.3,59.4,0.3864860206508294,0.3455631399317406,0.4761999601672974,0.5453827940015785,0.4048698237422491,0.1963608794541319,0.603682998924573,0.317
deepseek-ai/deepseek-coder-1.3b-base,DeepSeek-Coder,1.3,2.0,15.6,0.2602473161943855,0.257679180887372,0.3927504481179048,0.5272296764009471,0.4261368206487197,0.0295678544351781,0.6063458156415626,0.287
deepseek-ai/deepseek-coder-6.7b-base,DeepSeek-Coder,6.7,2.0,80.4,0.3839143097701981,0.3703071672354949,0.5345548695478988,0.5808997632202052,0.402813120561078,0.1796815769522365,0.6788708194897661,0.476
openlm-research/open_llama_3b_v2,OpenLlamaV2,3.0,1.0,18.0,0.2711798101137326,0.4027303754266211,0.7159928301135232,0.67008681925809,0.3477745324693538,0.0090978013646702,0.6629864333638158,0.0304878048780487
openlm-research/open_llama_7b,OpenLlama,7.0,1.0,42.0,0.3049340814990708,0.470136518771331,0.7197769368651663,0.6795580110497238,0.3484730707265278,0.0159211523881728,0.6784067802125662,0.0
openlm-research/open_llama_3b,OpenLlama,3.0,1.0,18.0,0.2693628703589735,0.3984641638225256,0.6264688309101772,0.6471981057616417,0.3496513582465124,0.0045489006823351,0.6303847286281321,0.0
openai-community/gpt2,GPT-2,0.124,,,0.2583371780486034,0.220136518771331,0.3152758414658435,0.5043409629044988,0.4069116400376613,0.0068233510235026,0.4836287229480824,0.0
openai-community/gpt2-medium,GPT-2,0.355,,,0.2682941553827826,0.2721843003412969,0.401911969727146,0.5398579321231255,0.407327593468292,0.0053070507960576,0.496118858232928,0.0
openai-community/gpt2-large,GPT-2,0.774,,,0.2606740306353156,0.257679180887372,0.4561840270862378,0.5540647198105761,0.3871845203558661,0.0083396512509476,0.4850483140145054,0.0
openai-community/gpt2-xl,GPT-2,1.5,,,0.2654916591422039,0.302901023890785,0.5139414459271061,0.580110497237569,0.3853406812051699,0.0090978013646702,0.5318969762491605,0.0
internlm/internlm2-7b,InternLM2,7.0,,,0.6524284758806714,0.5802047781569966,0.8123879705238001,0.8382004735595896,0.4872683928592292,0.6300227445034117,0.7590335542163101,
deepseek-ai/deepseek-llm-7b-base,DeepSeek-LLM,7.0,2.0,84.0,0.4924382663716678,0.5170648464163823,0.7811192989444333,0.7434885556432518,0.3492387119348669,0.1645185746777862,0.7538762023834483,0.2621951219512195
Deci/DeciLM-7B,DeciLM,7.0,,,0.5976293892443909,0.5938566552901023,0.8251344353714399,0.7995264404104183,0.4032625331106103,0.4738438210765731,,
stabilityai/stablelm-base-alpha-3b,StableLM,3.0,1.5,27.0,0.2543052660318274,0.2645051194539249,0.4224258115913165,0.5390686661404893,0.4049657855313842,0.0045489006823351,0.5331589710108058,0.0304878048780487
stabilityai/stablelm-base-alpha-7b-v2,StableLM,7.0,1.1,46.2,0.4509893993249705,0.4735494880546075,0.770762796255726,0.6850828729281768,0.3645720175160148,0.0257771038665655,0.693315855953262,0.1463414634146341
stabilityai/stablelm-2-1_6b,StableLM,1.6,2.0,19.200000000000003,0.3894657259915194,0.4334470989761092,0.7045409281019717,0.6456195737963694,0.3678385823884172,0.1743745261561789,0.6893882983321044,0.1036585365853658
stabilityai/stablelm-base-alpha-7b,StableLM,7.0,1.5,63.0,0.2620516094803125,0.3199658703071672,0.5178251344353715,0.5540647198105761,0.4019376597227457,0.0060652009097801,0.5622132966884474,0.024390243902439
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,RedPajama-INCITE-Base,7.0,1.0,42.0,0.2768214018695477,0.462457337883959,0.7162915753833897,0.6732438831886346,0.3303475420460559,0.0159211523881728,0.6363713635671634,0.048780487804878
togethercomputer/RedPajama-INCITE-Base-3B-v1,RedPajama-INCITE-Base,3.0,0.8,14.4,0.2702787422464126,0.401877133105802,0.647679745070703,0.6471981057616417,0.3323488684911484,0.0128885519332827,0.6389075983681398,0.0426829268292682
LLM360/Amber,Amber,7.0,1.259,52.87799999999999,0.2683568415711797,0.409556313993174,0.7379008165704043,0.6787687450670876,0.3355637385526089,0.0280515542077331,0.6711227637328238,0.0670731707317073
HuggingFaceTB/SmolLM-135M,SmolLM,0.135,0.6,0.486,0.2629112660847173,0.3199658703071672,0.4298944433379805,0.5240726124704025,0.3928152159562249,0.0106141015921152,0.4996838455850625,0.0
HuggingFaceTB/SmolLM-360M,SmolLM,0.36,0.6,1.296,0.2617017733266997,0.3907849829351535,0.5403306114319857,0.56353591160221,0.3804287604249111,0.0189537528430629,0.5297045167842469,0.0121951219512195
HuggingFaceTB/SmolLM-1.7B,SmolLM,1.7,1.0,10.2,0.301387707267915,0.4931740614334471,0.6725751842262497,0.6377269139700079,0.3850768934981668,0.0447308567096285,0.5572742616203735,0.024390243902439
cerebras/Cerebras-GPT-111M,Cerebras-GPT,0.111,0.00222,0.00147852,0.2551215002304024,0.2022184300341297,0.2672774347739494,0.4775059194948697,0.4631298313859067,0.0,0.5049043396944384,0.0
cerebras/Cerebras-GPT-256M,Cerebras-GPT,0.256,0.00512,0.00786432,0.2683072205019107,0.220136518771331,0.2898824935271858,0.5248618784530387,0.4597828347619155,0.0,0.5032943608953975,0.0060975609756097
cerebras/Cerebras-GPT-590M,Cerebras-GPT,0.59,0.0118,0.041772,0.2597134946363021,0.2372013651877133,0.3240390360485959,0.4814522494080505,0.441484541758896,0.0045489006823351,0.5099581425970716,0.0060975609756097
cerebras/Cerebras-GPT-1.3B,Cerebras-GPT,1.3,0.026,0.2028,0.2659293346313156,0.2627986348122867,0.385381398127863,0.5343330702446725,0.4269871364718513,0.0022744503411675,0.4756219238953617,0.0060975609756097
cerebras/Cerebras-GPT-2.7B,Cerebras-GPT,2.7,0.054,0.8748000000000001,0.2516691581900454,0.2909556313993174,0.4929296952798247,0.5414364640883977,0.4136763359861922,0.0045489006823351,0.511979811624888,0.0
cerebras/Cerebras-GPT-6.7B,Cerebras-GPT,6.7,0.134,5.386800000000001,0.2592839462676388,0.3506825938566553,0.5936068512248556,0.5872138910812944,0.3802394598585255,0.0053070507960576,0.6018660709332982,0.0853658536585365
cerebras/btlm-3b-8k-base,BTLM,3.0,627.0,11286.0,0.2716178134431024,0.4163822525597269,0.7090221071499702,0.6677190213101816,0.3591503187774632,0.0416982562547384,0.6514206058159508,0.1036585365853658
h2oai/h2o-danube-1.8b-base,H2O-Danube,1.8,1.0,10.8,0.259357407088472,0.39419795221843,0.6957777335192192,0.6448303078137332,0.3386425348954068,0.0144048521607278,0.6377463573512023,0.0060975609756097
h2oai/h2o-danube2-1.8b-base,H2O-Danube,1.8,3.0,32.400000000000006,0.4020066678115399,0.4334470989761092,0.7295359490141406,0.6803472770323599,0.3801259785228798,0.2979529946929492,0.648861931109778,0.0609756097560975
h2oai/h2o-danube3-500m-base,H2O-Danube,0.5,4.0,12.0,0.256073401566062,0.4061433447098976,0.6050587532364071,0.6172059984214681,0.37744444552282,0.1645185746777862,0.5797567282309688,0.0121951219512195
h2oai/h2o-danube3-4b-base,H2O-Danube,4.0,6.0,144.0,0.5458059831822469,0.5861774744027304,0.7984465245966939,0.7655880031570639,0.4413923587412932,0.400303260045489,0.6777411281945815,0.1280487804878048
allenai/OLMo-1B-hf,OLMo,1.0,3.0,18.0,0.2630669233808682,0.3455631399317406,0.6360286795459071,0.6108918705603789,0.3291625438037838,0.0189537528430629,0.5659539787509746,0.0548780487804878
allenai/OLMo-7B-hf,OLMo,7.0,2.5,105.0,0.281322718394009,0.4564846416382253,0.7730531766580363,0.6937647987371744,0.3592648258205651,0.0379075056861258,0.6650231930655283,0.1341463414634146
allenai/OLMo-7B-0424-hf,OLMo,7.0,2.05,86.1,0.534628987705994,0.4931740614334471,0.7862975502887871,0.728492501973165,0.3590780611634565,0.2676269901440485,0.7026214406944437,0.1707317073170731
TinyLlama/TinyLlama_v1.1,TinyLlama,1.1,3.0,19.8,0.2720582996634713,0.371160409556314,0.6267675761800439,0.6156274664561957,0.3508601784840882,0.0159211523881728,0.5962931267952212,0.0060975609756097
